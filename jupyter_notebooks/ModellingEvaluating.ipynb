{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Data Modelling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "- Business requirement 2:\n",
        "The client is interested in predicting if a cherry leaf is healthy or contains powdery mildew.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "- inputs/cherry_leaves_dataset/cherry-leaves/train\n",
        "- inputs/cherry_leaves_dataset/cherry-leaves/test\n",
        "- inputs/cherry_leaves_dataset/cherry-leaves/validation\n",
        "- Image shape embeddings\n",
        "\n",
        "## Outputs\n",
        "- Images distribution plot in train, validation, and test set.\n",
        "- label distribution - bar chart\n",
        "- set distriburion - pie chart (percentages)\n",
        "- Image augmentation.\n",
        "- plot augmented images for each set.\n",
        "- Class indices to change prediction inference in labels.\n",
        "- Creation of a Machine learning model and display of its summary\n",
        "- Model training.\n",
        "- Save model.\n",
        "- Learning curve plot for model performance.\n",
        "- Model A - separate plots for accuracy and loss\n",
        "- Model B - comprehensive model history plot\n",
        "- Model evaluation on saved file.\n",
        "- calculate accuracy\n",
        "- plot ROC curve\n",
        "- calculate classification report (Model A)\n",
        "- Model B - classification report with macro avg and weighted avg\n",
        "- Model C - syntetic classification report per label\n",
        "- Plot Confusion Matrix\n",
        "- Save evaluation pickle file\n",
        "- Prediction on the random image file.\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "- The code in the notebook analyzes the distribution of images across training, validation, and test sets, followed by augmenting these images for training using techniques such as rotation, zoom, and flipping. It defines a convolutional neural network (CNN) model for detecting powdery mildew in cherry leaves, trains it with callbacks for early stopping and model checkpointing, and evaluates its performance using metrics such as accuracy, loss, ROC curve, and confusion matrix. Finally, it saves the trained model, generates classification reports, and predicts the class of new images based on the modelâ€™s outputs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "import joblib\n",
        "sns.set_style(\"white\")\n",
        "from matplotlib.image import imread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "source": [
        "# Set Working Directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "outputs": [],
      "source": [
        "cwd= os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir('/workspace/mildew-detector-pp5')\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "work_dir = os.getcwd()\n",
        "work_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Set Input Directories\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sets the train, test and validation paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_data_dir = 'inputs/cherry_leaves_dataset/cherry-leaves'\n",
        "train_path = my_data_dir + '/train' \n",
        "valid_path = my_data_dir + '/validation'\n",
        "test_path = my_data_dir + '/test'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Set output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "outputs": [],
      "source": [
        "version = 'v1'\n",
        "file_path = f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
        "    print('Old version is already available create a new version.')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        " Set Label Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = os.listdir(train_path)\n",
        "print('Label for the images are', labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Set Image Shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "version = 'v1'\n",
        "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
        "image_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Images Distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These plots will give you a comprehensive view of your dataset's distribution across different labels and sets, which is essential for understanding data balance and preparing for model training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Count Number of Images per Set & Label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_img_freq = pd.DataFrame([])\n",
        "\n",
        "for folder in ['train', 'validation', 'test']:\n",
        "    for label in labels:\n",
        "        df_img_freq = df_img_freq.append(\n",
        "            pd.Series(\n",
        "                data={\n",
        "                    'Set': folder,\n",
        "                    'Label': label,\n",
        "                    'Frequency': int(len(os.listdir(my_data_dir + '/' + folder + '/' + label)))\n",
        "                }\n",
        "            ),\n",
        "            ignore_index=True\n",
        "        )\n",
        "\n",
        "        print(f\"* {folder} - {label}: {len(os.listdir(my_data_dir + '/' + folder + '/' + label))} images\")\n",
        "\n",
        "print(\"\\n\")\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=df_img_freq, x='Set', y='Frequency', hue='Label')\n",
        "plt.savefig(f'{file_path}/label_dist.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Image Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        " Import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Initialize ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "augmented_img_data = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.10,\n",
        "    height_shift_range=0.10,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    rescale=1./255\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set Batch Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Augment Training Image Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 1\n",
        "train_set = augmented_img_data.flow_from_directory(\n",
        "    train_path, \n",
        "    target_size=image_shape[:2],\n",
        "    color_mode='rgb',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "train_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Augment validation Image Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_img_data = ImageDataGenerator(rescale=1./255)\n",
        "validation_set = validation_img_data.flow_from_directory(\n",
        "    valid_path,\n",
        "    target_size=image_shape[:2],\n",
        "    color_mode='rgb',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "validation_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot Augmented Training Image Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "for _ in range(3):\n",
        "    plt.figure(figsize=(2, 2))\n",
        "    img, label = train_set.next()\n",
        "    print(img.shape)  \n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Augment Validation Image Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(valid_path,\n",
        "                                                                        target_size=image_shape[:2],\n",
        "                                                                        color_mode='rgb',\n",
        "                                                                        batch_size=batch_size,\n",
        "                                                                        class_mode='categorical',\n",
        "                                                                        shuffle=False\n",
        "                                                                        )\n",
        "\n",
        "validation_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot Augmented Validation Image Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    plt.figure(figsize=(2, 2))\n",
        "    img, label = validation_set.next()\n",
        "    print(img.shape)  \n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Augment Test Image Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
        "                                                                  target_size=image_shape[:2],\n",
        "                                                                  color_mode='rgb',\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  class_mode='categorical',\n",
        "                                                                  shuffle=False\n",
        "                                                                  )\n",
        "\n",
        "test_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot Augmented Test Image Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    plt.figure(figsize=(2, 2))\n",
        "    img, label = test_set.next()\n",
        "    print(img.shape)  \n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "joblib.dump(value=train_set.class_indices,\n",
        "            filename=f\"{file_path}/class_indices.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "ML Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The rationale for the model is explored in the README.md file of this project.\n",
        "- This model answers the Business Requirement #2: it's the final version of the model upon which the predictions will be based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_tf_model():\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # First convolutional layer\n",
        "    model.add(Conv2D(filters=16, kernel_size=(3, 3),\n",
        "              input_shape=image_shape, activation='relu', ))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Second convolutional layer\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
        "              input_shape=image_shape, activation='relu', ))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Third convolutional layer\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
        "              input_shape=image_shape, activation='relu', ))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Fourth convolutional layer\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3, 3),\n",
        "              input_shape=image_shape, activation='relu', ))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Fifth convolutional layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3, 3),\n",
        "              input_shape=image_shape, activation='relu', ))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "\n",
        "    # Prevent overfitting\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='SGD',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = generate_tf_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Callbacks are a powerful feature in machine learning, particularly when training models using libraries like TensorFlow and Keras. They provide a mechanism to control and customize the training process, allowing users to take specific actions at various stages of the training lifecycle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### EarlyStopping and ModelCheckPoint\n",
        "\n",
        "- EarlyStopping is used to monitor the val_accuracy (validation accuracy).\n",
        "- If the validation accuracy does not improve for a set number of epochs (patience=2 in your case), training will stop.\n",
        "- This prevents overfitting, where the model becomes too specialized on the training data and performs poorly on unseen data (like validation or test sets).\n",
        "--- \n",
        "- ModelCheckPoint monitors the val_accuracy and saves the model with the highest validation accuracy to the file path specified (outputs/v1/powdery_mildew_model.h5)\n",
        "- This ensures that you have a copy of the best-performing model, which is crucial if you want to avoid retraining the model from scratch or in case of any interruptions during training.\n",
        "- Saving only the best model also helps manage storage efficiently, especially if the training process runs for many epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "train_early_stop = EarlyStopping(monitor='val_loss', patience=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit Model for Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = generate_tf_model()\n",
        "history = model.fit(\n",
        "    train_set,\n",
        "    epochs=25,\n",
        "    steps_per_epoch=len(train_set.classes),\n",
        "    validation_data=validation_set,\n",
        "    callbacks=[train_early_stop],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('outputs/v1/powdery_mildew_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model Learning Curve A - Training, Validation, Loss & Accuracy Over Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "losses = pd.DataFrame(model.history.history)\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.set_style(\"whitegrid\")\n",
        "losses[['loss', 'val_loss']].plot(style='.-')\n",
        "plt.title(\"Loss\")\n",
        "plt.savefig(f'{file_path}/model_training_losses.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")\n",
        "losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.savefig(f'{file_path}/model_training_acc.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model Learning Curve B - Loss & Accuracy Over Training Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(model.history.history).plot(figsize=(8,5))\n",
        "plt.savefig(f'{file_path}/model_loss_acc.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('outputs/v1/powdery_mildew_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate Model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation = model.evaluate(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set Accuracy Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_set.reset()\n",
        "\n",
        "x_true, y_true = next(test_set)\n",
        "preds = np.argmax(model.predict(test_set), axis=1)\n",
        "y_pred = np.rint(preds)\n",
        "y_true = test_set.labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ROC Currve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc, accuracy_score, roc_auc_score\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_true, y_pred) # fpr: False Positive Rate, tpr: True Positive Rate\n",
        "roc_auc = auc(fpr, tpr) # Calculate the Area Under the Curve (AUC) for the ROC curve\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "lw = 2\n",
        "\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, label=\"Random classifier\", linestyle='--')\n",
        "\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "\n",
        "plt.xlabel('False Positive Rate (Specificity)')\n",
        "plt.ylabel('True Positive Rate (Sensitivity)')\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "plt.savefig(f'{file_path}/roccurve.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "print('Area Under ROC-Curve: ', roc_auc_score(y_true, y_pred))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "cm = confusion_matrix(y_true,y_pred)\n",
        "\n",
        "classes=list(test_set.class_indices.keys()) \n",
        "length=len(classes)\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n",
        "plt.xticks(np.arange(length)+.5, classes, rotation= 0, fontsize=8)\n",
        "plt.yticks(np.arange(length)+.3, classes, rotation=90, fontsize=8)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.savefig(f'{file_path}/confusion_matrix.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classification Report - A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Classification Report:\\n----------------------\\n')\n",
        "print(classification_report(y_true, y_pred, target_names=labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classification Report - B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "clf_report = classification_report(y_true, y_pred, target_names=labels, output_dict=True)\n",
        "fig, ax = plt.subplots(figsize=(8,5))\n",
        "sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True, cmap=\"Blues\", cbar=False, linewidths=1)\n",
        "plt.title('Classification Report')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classificaiton Report - C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "import pathlib\n",
        "\n",
        "def plot_classification_report(y_test, y_pred, title='Classification Report', save_fig_path=None, **kwargs):\n",
        "    fig, ax = plt.subplots(figsize=(8,5))    \n",
        "    clf_report = classification_report(y_true, y_pred, output_dict=True, **kwargs)\n",
        "    keys_to_plot = [key for key in clf_report.keys() if key not in ('accuracy', 'macro avg', 'weighted avg')]\n",
        "    df = pd.DataFrame(clf_report, columns=keys_to_plot).T\n",
        "    df.sort_values(by=['support'], inplace=True) \n",
        "    \n",
        "    rows, cols = df.shape\n",
        "    mask = np.zeros(df.shape)\n",
        "    mask[:,cols-1] = True\n",
        " \n",
        "    ax = sns.heatmap(df, mask=mask, annot=True, cmap=\"YlGn\", fmt='.3g', cbar=False,\n",
        "            vmin=0.0,\n",
        "            vmax=1.0,\n",
        "            linewidths=.4, linecolor='white'\n",
        "                    )\n",
        "    \n",
        "    mask = np.zeros(df.shape)\n",
        "    mask[:,:cols-1] = True    \n",
        "    \n",
        "    ax = sns.heatmap(df, mask=mask, annot=True, cmap=\"YlGn\", cbar=False,\n",
        "            linewidths=2, linecolor='white', fmt='.0f',\n",
        "            vmin=df['support'].min(),\n",
        "            vmax=df['support'].sum(),         \n",
        "            norm=mpl.colors.Normalize(vmin=df['support'].min(),\n",
        "                                      vmax=df['support'].sum())\n",
        "                    ) \n",
        "            \n",
        "    plt.title(title)\n",
        "    plt.yticks(np.arange(length)+.2, classes, rotation=90)\n",
        "         \n",
        "    if (save_fig_path != None):\n",
        "        path = pathlib.Path(save_fig_path)\n",
        "        path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        fig.savefig(save_fig_path)\n",
        "    \n",
        "    return fig, ax\n",
        "\n",
        "fig, ax = plot_classification_report(y_true, y_pred, \n",
        "                    title='Classification Report',\n",
        "                    target_names=labels,\n",
        "                    save_fig_path = f'{file_path}/clf_report.png',)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save Evaluation Pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "joblib.dump(value=evaluation,\n",
        "            filename=f\"outputs/v1/evaluation.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict On New Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Random Image as PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "pointer = 32\n",
        "label = labels[1] # select 0 for 'healthy' or 1 for 'powdery_mildew'\n",
        "\n",
        "pil_image = image.load_img(test_path + '/' + label + '/' + os.listdir(test_path+'/' + label)[pointer],\n",
        "                           target_size=image_shape, color_mode='rgb')\n",
        "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
        "pil_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert Image To Array & Prepare for Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_image = image.img_to_array(pil_image)\n",
        "my_image = np.expand_dims(my_image, axis=0)/255\n",
        "print(my_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Predict Class Probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "pred_proba = model.predict(my_image)[0, 0]\n",
        "\n",
        "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
        "pred_class = target_map[pred_proba < 0.5]\n",
        "\n",
        "if pred_class == target_map[1]:\n",
        "    pred_proba = 1 - pred_proba\n",
        "\n",
        "print(f\"{pred_class} {round(pred_proba*100, 2)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Push files to Repo\n",
        "\n",
        "### Push new files from this Session to the GitHub repo\n",
        "\n",
        "- .gitignore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cat .gitignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git status"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
